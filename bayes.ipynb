{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_class(mydata):\n",
    "\tclasses = []\n",
    "\tfor i in range(len(mydata)):\n",
    "\t\tif mydata[i][-1] not in classes:\n",
    "\t\t\tclasses.append(mydata[i][-1])\n",
    "\tfor i in range(len(classes)):\n",
    "\t\tfor j in range(len(mydata)):\n",
    "\t\t\tif mydata[j][-1] == classes[i]:\n",
    "\t\t\t\tmydata[j][-1] = i\n",
    "\treturn mydata\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(mydata, ratio):\n",
    "\ttrain_num = int(len(mydata) * ratio)\n",
    "\ttrain = []\n",
    "\t# initially testset will have all the dataset\n",
    "\ttest = list(mydata)\n",
    "\twhile len(train) < train_num:\n",
    "\t\t# index generated randomly from range 0\n",
    "\t\t# to length of testset\n",
    "\t\tindex = random.randrange(len(test))\n",
    "\t\t# from testset, pop data rows and put it in train\n",
    "\t\ttrain.append(test.pop(index))\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupUnderClass(mydata):\n",
    "\tdict = {}\n",
    "\tfor i in range(len(mydata)):\n",
    "\t\tif (mydata[i][-1] not in dict):\n",
    "\t\t\tdict[mydata[i][-1]] = []\n",
    "\t\tdict[mydata[i][-1]].append(mydata[i])\n",
    "\treturn dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "\treturn sum(numbers) / float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_dev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "\treturn math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanAndStdDev(mydata):\n",
    "\tinfo = [(mean(attribute), std_dev(attribute)) for attribute in zip(*mydata)]\n",
    "\tdel info[-1]\n",
    "\treturn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanAndStdDevForClass(mydata):\n",
    "\tinfo = {}\n",
    "\tdict = groupUnderClass(mydata)\n",
    "\tfor classValue, instances in dict.items():\n",
    "\t\tinfo[classValue] = MeanAndStdDev(instances)\n",
    "\treturn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateGaussianProbability(x, mean, stdev):\n",
    "\texpo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "\treturn (1 / (math.sqrt(2 * math.pi) * stdev)) * expo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(info, test):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in info.items():\n",
    "\t\tprobabilities[classValue] = 1\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, std_dev = classSummaries[i]\n",
    "\t\t\tx = test[i]\n",
    "\t\t\tprobabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
    "\treturn probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(info, test):\n",
    "\tprobabilities = calculateClassProbabilities(info, test)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(info, test):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(test)):\n",
    "\t\tresult = predict(info, test[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_rate(test, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(test)):\n",
    "\t\tif test[i][-1] == predictions[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct / float(len(test))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'bayesdata.csv'\n",
    "\n",
    "\n",
    "# load the file and store it in mydata list\n",
    "mydata = csv.reader(open(filename, \"rt\"))\n",
    "mydata = list(mydata)\n",
    "mydata = encode_class(mydata)\n",
    "for i in range(len(mydata)):\n",
    "\tmydata[i] = [float(x) for x in mydata[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples are:  768\n",
      "Out of these, training examples are:  537\n",
      "Test examples are:  231\n",
      "Accuracy of your model is:  77.48917748917748\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.7\n",
    "train_data, test_data = splitting(mydata, ratio)\n",
    "print('Total number of examples are: ', len(mydata))\n",
    "print('Out of these, training examples are: ', len(train_data))\n",
    "print(\"Test examples are: \", len(test_data))\n",
    "\n",
    "# prepare model\n",
    "info = MeanAndStdDevForClass(train_data)\n",
    "\n",
    "# test model\n",
    "predictions = getPredictions(info, test_data)\n",
    "accuracy = accuracy_rate(test_data, predictions)\n",
    "print(\"Accuracy of your model is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4cc0a6c0319b1569e2b81a1d029675795e459fc469682d89b44aaf2ebf1a14d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
